{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing statistics from trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import contracts\n",
    "contracts.disable_all()\n",
    "\n",
    "import drawSvg as draw\n",
    "import geometry as geo\n",
    "import math\n",
    "import numpy as np\n",
    "from os import path, listdir\n",
    "from scipy import stats\n",
    "import yaml\n",
    "\n",
    "import duckietown_world as dw\n",
    "from duckietown_world.svg_drawing.ipython_utils import ipython_draw_svg, ipython_draw_html\n",
    "from duckietown_world.world_duckietown.tile import get_lane_poses\n",
    "from duckietown_world import draw_static\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of the notebook\n",
    "\n",
    "Familiarize yourself with duckietown world, with an example. The goal is to plot the average trajectory along with its standard deviation for a set of experiments done on fixed map and starting conditions. \n",
    "\n",
    "Let's start with visualizing the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dw.load_map('Montreal_loop')\n",
    "\n",
    "ipython_draw_svg(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utilities that we are going to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AFakeBar(dw.PlacedObject):\n",
    "    \"Ellipse object with a large ration between the radii\"\n",
    "\n",
    "    def __init__(self, len=0, fill_opacity=0.5, color='pink', *args, **kwargs):\n",
    "        self.len = len\n",
    "        self.fill_opacity = fill_opacity\n",
    "        self.color = color\n",
    "        dw.PlacedObject.__init__(self, *args, **kwargs)\n",
    "\n",
    "    def draw_svg(self, drawing, g):\n",
    "        # drawing is done using the library svgwrite\n",
    "        c = drawing.ellipse(center=(0, 0), r=(0.03,self.len), fill=self.color, fill_opacity=self.fill_opacity)\n",
    "        g.add(c)\n",
    "        # draws x,y axes\n",
    "        dw.draw_axes(drawing, g)\n",
    "        \n",
    "\n",
    "class Circle(dw.PlacedObject):\n",
    "    \"Circle object.\"\n",
    "\n",
    "    def __init__(self, radius, color='pink', *args, **kwargs):\n",
    "        self.radius = radius\n",
    "        self.color = color\n",
    "        dw.PlacedObject.__init__(self, *args, **kwargs)\n",
    "\n",
    "    def draw_svg(self, drawing, g):\n",
    "        # drawing is done using the library svgwrite\n",
    "        c = drawing.circle(center=(0, 0), r=self.radius, fill=self.color)\n",
    "        g.add(c)\n",
    "        # draws x,y axes\n",
    "        dw.draw_axes(drawing, g)\n",
    "\n",
    "    def extent_points(self):\n",
    "        # set of points describing the boundary\n",
    "        L = self.radius\n",
    "        return [(-L, -L), (+L, +L)]\n",
    "\n",
    "\n",
    "def relative_pose(q0, q1):\n",
    "    \"Computes the relative pose between two points in SE2\"\n",
    "    return geo.SE2.multiply(geo.SE2.inverse(q0), q1)\n",
    "\n",
    "\n",
    "def interpolate(q0, q1, alpha):\n",
    "    \"Interpolates between two points in SE2, given a coefficient alpha.\"\n",
    "    q1_from_q0 = relative_pose(q0, q1)\n",
    "    vel = geo.SE2.algebra_from_group(q1_from_q0)\n",
    "    rel = geo.SE2.group_from_algebra(vel * alpha)\n",
    "    q = geo.SE2.multiply(q0, rel)\n",
    "    return q\n",
    "\n",
    "\n",
    "def extract_trajectory(localization_log):\n",
    "    \"From a log file from the localization system, extract a list of transforms describing the trajectory.\"\n",
    "\n",
    "    final_trajectory = []\n",
    "\n",
    "    len_trajectory = len(localization_log['trajectory_data'])\n",
    "    x, y = np.zeros(len_trajectory), np.zeros(len_trajectory)\n",
    "    R = np.zeros((3, 3, len_trajectory))\n",
    "    phi = np.zeros((3, len_trajectory))\n",
    "\n",
    "    for i, (time, traj) in enumerate(localization_log['trajectory_data'].items()):\n",
    "        x[i] = np.array(traj[0])\n",
    "        y[i] = np.array(traj[1])\n",
    "\n",
    "        R[:, :, i] = np.reshape(np.array(traj[3:]), (3, 3))\n",
    "        phi[:, i] = np.array([np.arctan2(-R[1, 2, i], R[2, 2, i]),\n",
    "                              np.arctan2(R[0, 2, i], np.sqrt(R[0, 0, i] ** 2 + R[0, 1, i] ** 2)),\n",
    "                              np.arctan2(-R[0, 1, i], R[0, 0, i])])\n",
    "\n",
    "        z = phi[2, i]\n",
    "        points = np.array([x[i], y[i]])\n",
    "        final_trajectory.append([points, z])\n",
    "    final_array = final_trajectory.copy()\n",
    "\n",
    "    traj_tfs = []\n",
    "    for entry in range(0, len(final_array)):\n",
    "        x, y = final_array[entry][0][0:2]\n",
    "        theta = final_array[entry][1]\n",
    "        q = geo.SE2_from_translation_angle([x, y], theta)\n",
    "        traj_tfs.append(q)\n",
    "\n",
    "    return traj_tfs\n",
    "\n",
    "\n",
    "def get_interpolated_points(center_line, trajectories):\n",
    "    \"\"\"Generates an interpolated point for each point on the center line, for each trajectory as long as the point\n",
    "    lies between two trajectory points.\"\"\"\n",
    "    closest_behind = [None] * len(trajectories)\n",
    "    interpolated_trajectories = []\n",
    "    for center_point in center_line:\n",
    "        interpolated_points = []\n",
    "        for idx_t, traj in enumerate(trajectories):\n",
    "            interpolated_point_traj = None\n",
    "            begin_t = closest_behind[idx_t] if closest_behind[idx_t] else 0\n",
    "            for idx_point in range(begin_t, len(traj)):\n",
    "                if a_behind_b(a=traj[idx_point], b=center_point):\n",
    "                    closest_behind[idx_t] = idx_point\n",
    "                    continue\n",
    "\n",
    "                if closest_behind[idx_t] is None:\n",
    "                    # If there is no point behind we cannot compute the interpolation\n",
    "                    interpolated_point_traj = None\n",
    "                    break\n",
    "                else:\n",
    "                    try:\n",
    "                        interpolated_point_traj = interpolate_magic(center_point,\n",
    "                                                                    traj[closest_behind[idx_t]],\n",
    "                                                                    traj[closest_behind[idx_t] + 1])\n",
    "                        break\n",
    "\n",
    "                    except IndexError:\n",
    "                        print('The index is outside the list!')\n",
    "                        interpolated_point_traj = None\n",
    "                        break\n",
    "            interpolated_points.append(interpolated_point_traj)\n",
    "        interpolated_trajectories.append(interpolated_points)\n",
    "    return interpolated_trajectories\n",
    "\n",
    "\n",
    "def a_behind_b(a=None, b=None):\n",
    "    \"\"\"Check if a is behind b wrt the heading direction of a.\"\"\"\n",
    "    if a is None or b is None:\n",
    "        return False\n",
    "    rel_pose = relative_pose(b, a)\n",
    "    return dw.SE2Transform.from_SE2(rel_pose).p[0] < 0\n",
    "\n",
    "\n",
    "def interpolate_magic(center_pt, previous_pt, next_pt):\n",
    "    \"\"\"Returns an interpolated point between previoust_pt and next_pt at the height of center_pt\"\"\"\n",
    "    tf_prev = relative_pose(center_pt, previous_pt)\n",
    "    d_prev = dw.SE2Transform.from_SE2(tf_prev).p[0]\n",
    "\n",
    "    tf_next = relative_pose(center_pt, next_pt)\n",
    "    d_next = dw.SE2Transform.from_SE2(tf_next).p[0]\n",
    "\n",
    "    alpha = np.abs(d_prev) / (np.abs(d_prev) + d_next)\n",
    "    interpolated_pt = interpolate(previous_pt, next_pt, alpha)\n",
    "    return interpolated_pt\n",
    "\n",
    "\n",
    "def get_used_lanes(trajectories):\n",
    "    \"\"\"Returns a list with all used lanes and a dictionary containing the transform to each lane segment.\"\"\"\n",
    "    used_lane_segs = set()\n",
    "    used_lane_segs_list = []\n",
    "    lane_segs_tfs = dict()\n",
    "\n",
    "    for traj in trajectories:\n",
    "        for pose in traj:\n",
    "            try:\n",
    "                tl = list(get_lane_poses(m, pose))[0]\n",
    "                lane_segment_name = tl.lane_segment_fqn\n",
    "\n",
    "                if lane_segment_name not in used_lane_segs:\n",
    "                    used_lane_segs.add(lane_segment_name)\n",
    "                    used_lane_segs_list.append(lane_segment_name)\n",
    "                    lane_segs_tfs[lane_segment_name] = tl.lane_segment_transform.asmatrix2d().m\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return used_lane_segs_list, lane_segs_tfs\n",
    "\n",
    "\n",
    "def get_global_center_line(map, used_lane_segs, global_segs_SE2, pts_per_segment):\n",
    "    \"Builds a center line for all the used lanes in the global coordinate frame.\"\n",
    "    center_line = []\n",
    "    center_line_global = []\n",
    "    center_line_global_tfs = []\n",
    "\n",
    "    for i, lane_segment in enumerate(used_lane_segs):\n",
    "        if lane_segment[2] == 'straight':\n",
    "            n_inter = pts_per_segment['mid']\n",
    "        elif lane_segment[-1] == 'lane2':\n",
    "            n_inter = pts_per_segment['long']\n",
    "        elif lane_segment[-1] == 'lane1':\n",
    "            n_inter = pts_per_segment['short']\n",
    "        lane = map[lane_segment]\n",
    "\n",
    "        # The end point is part of next tile\n",
    "        steps = np.linspace(0, len(lane.control_points) - 1, num=n_inter, endpoint=False)\n",
    "\n",
    "        for beta in steps:\n",
    "            center_point_local_SE2 = lane.center_point(beta)\n",
    "            center_line.append(center_point_local_SE2)\n",
    "\n",
    "            # get SE2 of the point in global coords\n",
    "            center_point_global_SE2 = geo.SE2.multiply(global_segs_SE2[lane_segment],\n",
    "                                                       center_point_local_SE2)\n",
    "\n",
    "            center_line_global.append(center_point_global_SE2)\n",
    "            center_line_global_tfs.append(dw.SE2Transform.from_SE2(center_point_global_SE2))\n",
    "    return center_line_global, center_line_global_tfs\n",
    "\n",
    "def get_trajectories_statistics(trajectories):\n",
    "    \"\"\"Computes mean trajectory and std deviations for y and angle given a list of trajectories sampled at the same x\"\"\"\n",
    "    mean_tfs = []\n",
    "    std_y = []\n",
    "    std_heading = []\n",
    "\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "    # We need to find the first amd last index for which all trajectories have a point\n",
    "    for idx, trajs_points in enumerate(trajectories):\n",
    "        if all(trajs_points) and start_idx is None:\n",
    "            start_idx = idx\n",
    "        elif not all(trajs_points) and start_idx is not None:\n",
    "            end_idx = idx\n",
    "            break\n",
    "    end_idx = -1 if end_idx is None else end_idx\n",
    "    complete_trajectories = trajectories[start_idx:end_idx]\n",
    "    for tfs in complete_trajectories:\n",
    "        xs = [tf.p[0] for tf in tfs]\n",
    "        ys = [tf.p[1] for tf in tfs]\n",
    "        headings = [tf.theta for tf in tfs]\n",
    "        mean_x = np.mean(xs)\n",
    "        mean_y = np.mean(ys)\n",
    "        # To compute mean angles we need to pay attention\n",
    "        mean_angle = np.arctan2(np.mean(np.sin(headings)),np.mean(np.cos(headings)))\n",
    "        \n",
    "        mean_tfs.append(dw.SE2Transform.from_SE2(geo.SE2_from_translation_angle([mean_x, mean_y], mean_angle)))\n",
    "        \n",
    "        \n",
    "        # Compute all transforms wrt to the mean trajectory to compute the standard deviations\n",
    "        #lateral_deviation = [(mean_x-t.p[0])*np.sin(t.theta)+(mean_y-t.p[1])*np.cos(t.theta) for t in tfs]\n",
    "        lateral_deviation = []\n",
    "        mean_point = geo.SE2_from_translation_angle([mean_x, mean_y], mean_angle)\n",
    "        for t in tfs:\n",
    "            relative_tf = dw.SE2Transform.from_SE2(relative_pose(mean_point, t.as_SE2()))\n",
    "            lateral_deviation.append(relative_tf.p[1])\n",
    "\n",
    "        std_y.append(np.std(lateral_deviation))\n",
    "        std_heading.append(stats.circstd(headings, low=-math.pi, high=math.pi))\n",
    "        \n",
    "    return mean_tfs, std_y, std_heading, start_idx, end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "First of all, we need to load some trajectories from the logs of the localization system. For this demo, we are going to use multiple evaluations on the same map, the logs are stored in the `logs` directory. If you have your own data, you can change the `experiment_dir` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = ''\n",
    "\n",
    "logs_path = path.join(experiment_dir, 'logs')\n",
    "\n",
    "localization_logs = [path.join(logs_path, f) for f in listdir(logs_path) if path.isfile(path.join(logs_path, f))]\n",
    "print(f'Logs found: {localization_logs}')\n",
    "\n",
    "all_logs = []\n",
    "for filename in localization_logs:\n",
    "    with open(filename, 'r') as file:\n",
    "        all_logs.append(yaml.safe_load(file))\n",
    "        \n",
    "# Load the evaluation map\n",
    "m = dw.load_map('Montreal_loop')\n",
    "\n",
    "# Get a list of all trajectories, each saved as list of transforms\n",
    "all_trajectories = []\n",
    "for log in all_logs:\n",
    "    all_trajectories.append(extract_trajectory(log))\n",
    "\n",
    "used_lane_segments_list, lane_segments_SE2 = get_used_lanes(all_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the average trajectory\n",
    "\n",
    "Once we have our trajectories loaded, we can start to compute our average trajectory. To do so we first compute a center line that passes through each lane segment on which our Duckiebot passed. This will be used as a reference to re-sample the trajectories in order to have coherent data for comparison and averaging.\n",
    "\n",
    "This part will take a lot of time if your map is very complex (i.e. `robotarium2`). This will improve once tile map and signal map get separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del m    \n",
    "except:\n",
    "    pass\n",
    "m = dw.load_map('Montreal_loop')\n",
    "\n",
    "# Number of interpolation points of a straight tile\n",
    "mid = 30\n",
    "\n",
    "# Number of interpolation points of each tile (approximation, need to do it properly)\n",
    "pts_per_segment = {\n",
    "    'short': int(mid*1/8*math.pi),\n",
    "    'mid': mid,\n",
    "    'long': int(mid*3/8*math.pi),\n",
    "}\n",
    "\n",
    "# Compute the center line that we will use to resample\n",
    "center_line_global, center_line_global_tfs = get_global_center_line(m,\n",
    "                                                                    used_lane_segments_list,\n",
    "                                                                    lane_segments_SE2,\n",
    "                                                                    pts_per_segment)\n",
    "\n",
    "# Base transform if the plotting map is not the same as the evaluation map (i.e. plotting a subset \n",
    "# of a large map containing muliple loops)\n",
    "base_transform = np.linalg.inv(geo.SE2_from_translation_angle([0.585 * 0, 0.0], 0))\n",
    "\n",
    "# Compute the interpolated trajectories\n",
    "int_trajs = get_interpolated_points(center_line_global, all_trajectories)\n",
    "\n",
    "# Compute the transforms of those trajectories for plotting\n",
    "all_int_tfs = []\n",
    "for traj in int_trajs:\n",
    "    int_tfs_traj = []\n",
    "    for el in traj:\n",
    "        if el is not None:\n",
    "            int_tfs_traj.append(dw.SE2Transform.from_SE2(geo.SE2.multiply(base_transform, el)))\n",
    "        else:\n",
    "            int_tfs_traj.append(None)\n",
    "    all_int_tfs.append(int_tfs_traj)\n",
    "\n",
    "# Finally, compute the statistics on the resampled trajectory\n",
    "mean_tfs, std_y, std_angle, start_idx, end_idx = get_trajectories_statistics(all_int_tfs)\n",
    "\n",
    "# Load the plotting map, this can be different than the previous map (for example, if you don't want apriltags\n",
    "# in the final plot.)\n",
    "del m\n",
    "m = dw.load_map('Montreal_loop')\n",
    "\n",
    "# Create objects for drawing\n",
    "for i, meant_tf in enumerate(mean_tfs):\n",
    "    if not(i%2):\n",
    "        m.set_object(str(i + 10000), Circle(0.01, color='purple'), ground_truth=meant_tf)\n",
    "for i, meant_tf in enumerate(mean_tfs):\n",
    "    m.set_object(str(i + 1000), AFakeBar(len=std_y[i], color='green'), ground_truth=meant_tf)\n",
    "\n",
    "# Draw!\n",
    "outdir = path.join('/home/gianmarco/out', \"ipython_draw_svg\", \"%s\" % id(m))\n",
    "\n",
    "ipython_draw_svg(m);\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data\n",
    "If you care about the statistics, you can save the data to some directory. You can find the `svg` drawings in the `out/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything, just in case\n",
    "# Save map as yaml file\n",
    "outdir = path.join(experiment_dir, 'out')\n",
    "outmap = path.join(outdir, 'out.yaml')\n",
    "with open(outmap, 'w') as yaml_file:\n",
    "    yaml.dump(m, yaml_file, default_flow_style=False)\n",
    "\n",
    "# Save statistics of average trajectory\n",
    "d = []\n",
    "phi = []\n",
    "for tf in mean_tfs:\n",
    "    point =tf.as_SE2()\n",
    "    data = list(get_lane_poses(m, point))[0]\n",
    "    d.append(data.lane_pose.lateral)\n",
    "    \n",
    "    phi.append(data.lane_pose.relative_heading)\n",
    "    \n",
    "import pandas as pd\n",
    "outstats = path.join(outdir, 'stats.csv')\n",
    "df = pd.DataFrame(data={\"d\": d,\n",
    "                            \"std_y\": std_y,\n",
    "                            \"phi\": phi,\n",
    "                            \"std_heading\": std_angle})\n",
    "df.to_csv(outstats, sep=',', index=False)\n",
    "\n",
    "# Save slow part of code\n",
    "outdir = path.join(experiment_dir, 'out')\n",
    "files = [path.join(outdir,'used_lane_segments_list.yaml'),\n",
    "         path.join(outdir, 'lane_segments_SE2.yaml')]\n",
    "data = [used_lane_segments_list, lane_segments_SE2]\n",
    "\n",
    "for file,data in zip(files,data):\n",
    "    with open(file, 'w') as yaml_file:\n",
    "        yaml.dump(data, yaml_file, default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
